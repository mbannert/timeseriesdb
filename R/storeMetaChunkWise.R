#' Store Meta Information Chunk Wise to Avoid Memory Problem
#' 
#' This function is a wrapper around \code{\link{updateMetaInformation}}. It is used to split large environments of meta info
#' to avoid memory limitations. This function uses INSERT INTO instead of the more convenient dbWritetable for performance reasons. DO NOT USE THIS FUNCTIONS IN LOOPS OR LAPPLY! This function can handle a set of time series on its own and is much faster than looping over a list. Non-unique primary keys are overwritten !
#' 
#' @param meta_envir object of class meta_env. Most likely
#' generated by \code{\link{addMetaInformation}}
#' @param con a PostgreSQL connection object
#' @param schema character name of the schema to write to. Defaults to 'timeseries'.
#' @param tbl character name of the meta information table to write to. 
#' Defaults to 'meta_data_unlocalized'.
#' @param keys character vector of time series. If specified only the selected 
#' meta information is stored. Defaults to NULL which stores all meta information
#' records in the environment. 
#' @export
storeMetaChunkWise <- function(meta_envir,con,
                               schema = "timeseries",
                               tbl = "meta_data_unlocalized",
                               keys=NULL){
  
  chunks <- ceiling(as.numeric(object.size(as.list(meta_envir)))/(Cstack_info()["size"]*0.7))
  nms <- ls(envir=meta_envir)
  name_chunks <- split(nms,ceiling(seq_along(nms/chunks)))
  
  # loop over the chunks in order to store it chunk wise 
  # otherwise we run into stack limit on the server
  for(i in seq_along(name_chunks)){
    updateMetaInformation(meta_envir,con,
             schema,
             tbl,
             keys=name_chunks[i]) 
  }
}



